import os
import sys
import shutil
import tempfile

# ä¼˜å…ˆè®¾ç½® SSL è¯ä¹¦è·¯å¾„ï¼Œé¿å… curl/requests æŠ¥é”™ 77ï¼ˆWindows ä¸‹è·¯å¾„å«ä¸­æ–‡æ—¶ curl æ— æ³•æ­£ç¡®è¯»å–ï¼‰
def _path_has_non_ascii(p):
    return p != p.encode("ascii", errors="replace").decode("ascii")

def _setup_ssl_cert():
    try:
        import certifi
        _cacert = certifi.where()
        # è·¯å¾„å«ä¸­æ–‡æˆ–ä¸º Windows æ—¶ï¼Œcurl å¸¸æŠ¥ 77ï¼Œå°†è¯ä¹¦å¤åˆ¶åˆ°çº¯è‹±æ–‡è·¯å¾„å†æŒ‡å®š
        if _path_has_non_ascii(_cacert) or sys.platform == "win32":
            for _dir in (tempfile.gettempdir(), os.environ.get("LOCALAPPDATA", ""), "C:\\Windows\\Temp"):
                if _dir and os.path.isdir(_dir) and not _path_has_non_ascii(_dir):
                    _dest = os.path.join(_dir, "cacert_daily_stock.pem")
                    try:
                        if not os.path.exists(_dest) or os.path.getmtime(_dest) < os.path.getmtime(_cacert):
                            shutil.copy2(_cacert, _dest)
                        os.environ["SSL_CERT_FILE"] = _dest
                        os.environ["REQUESTS_CA_BUNDLE"] = _dest
                        break
                    except OSError:
                        continue
        else:
            os.environ.setdefault("SSL_CERT_FILE", _cacert)
            os.environ.setdefault("REQUESTS_CA_BUNDLE", _cacert)
    except Exception:
        pass

_setup_ssl_cert()

import streamlit as st
import time
from datetime import datetime, timedelta
import akshare as ak
from google import genai
from google.genai import types
import pandas as pd
from dotenv import load_dotenv

# å¯¼å…¥pipelineæ¨¡å—
from src.core.pipeline import StockAnalysisPipeline
from src.enums import ReportType
from src.analyzer import STOCK_NAME_MAP
from src.auth import register, login
from src.usage_tracker import record_usage
from datetime import date as date_type

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Aè‚¡åˆ†æåŠ©æ‰‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åŠ è½½ç¯å¢ƒå˜é‡ï¼šä» run_new.py æ‰€åœ¨ç›®å½•åŠ è½½ .envï¼Œé¿å…å·¥ä½œç›®å½•å¯¼è‡´æ‰¾ä¸åˆ°
_env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".env")
load_dotenv(_env_path)

# --- æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨ cache_resource ä¿æŒ Client è¿æ¥æ´»è·ƒ ---
@st.cache_resource
def get_gemini_client():
    """
    ä½¿ç”¨ st.cache_resource ç¼“å­˜å®¢æˆ·ç«¯å®ä¾‹ã€‚
    é˜²æ­¢ Streamlit æ¯æ¬¡ Rerun æ—¶é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯å¯¼è‡´æ—§è¿æ¥è¢«å…³é—­ã€‚
    ä»£ç† URL å¯é€šè¿‡ GEMINI_PROXY_URL ç¯å¢ƒå˜é‡é…ç½®ï¼ˆå¦‚ socks5://127.0.0.1:10808 æˆ– http://VPS_IP:8888ï¼‰ã€‚
    """
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("âŒ æœªæ£€æµ‹åˆ° GEMINI_API_KEYï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡æˆ– .env æ–‡ä»¶")
        return None
    # ä»…å¯¹ Gemini ä½¿ç”¨ä»£ç†ï¼Œä¸è®¾ç½®å…¨å±€ HTTP_PROXYï¼Œé¿å…å›½å†…æ¥å£(Tushare/è…¾è®¯/æ–°æµª)ä¹Ÿèµ°ä»£ç†å¯¼è‡´å¤±è´¥
    proxy_url = os.getenv("GEMINI_PROXY_URL", "socks5h://127.0.0.1:10808")
    client = genai.Client(
        api_key=api_key,
        http_options=types.HttpOptions(
            client_args={"proxy": proxy_url} if proxy_url else {},
            async_client_args={"proxy": proxy_url} if proxy_url else {},
        )
    )
    return client

# è·å–å…¨å±€å”¯ä¸€çš„ client å®ä¾‹
client = get_gemini_client()

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .stTextArea textarea { font-size: 14px; }
    .block-container { padding-top: 2rem; }
    .stChatMessage { border-radius: 10px; margin-bottom: 10px; }
</style>
""", unsafe_allow_html=True)

# --- 1.5 ç”¨æˆ·è®¤è¯ï¼ˆéœ€æ³¨å†Œ/ç™»å½•åæ‰èƒ½ä½¿ç”¨ï¼‰---
_auth_required = os.getenv("AUTH_REQUIRED", "true").lower() in ("true", "1", "yes")
if "current_user" not in st.session_state:
    st.session_state.current_user = None

if _auth_required and st.session_state.current_user is None:
    st.title("ğŸ“ˆ æ™ºèƒ½è‚¡ç¥¨åˆ†æåŠ©æ‰‹")
    st.caption("ä½¿ç”¨å‰è¯·å…ˆç™»å½•æˆ–æ³¨å†Œ")
    tab1, tab2 = st.tabs(["ç™»å½•", "æ³¨å†Œ"])
    with tab1:
        with st.form("login_form"):
            login_user = st.text_input("ç”¨æˆ·å")
            login_pwd = st.text_input("å¯†ç ", type="password")
            if st.form_submit_button("ç™»å½•"):
                ok, user, msg = login(login_user, login_pwd)
                if ok and user:
                    st.session_state.current_user = user
                    st.success(msg)
                    st.rerun()
                else:
                    st.error(msg)
    with tab2:
        with st.form("register_form"):
            reg_user = st.text_input("ç”¨æˆ·åï¼ˆè‡³å°‘2ä½ï¼‰")
            reg_pwd = st.text_input("å¯†ç ï¼ˆè‡³å°‘6ä½ï¼‰", type="password")
            reg_email = st.text_input("é‚®ç®±ï¼ˆå¿…å¡«ï¼‰")
            reg_phone = st.text_input("æ‰‹æœºå·ï¼ˆå¿…å¡«ï¼‰")
            if st.form_submit_button("æ³¨å†Œ"):
                ok, msg = register(reg_user, reg_pwd, reg_email, reg_phone)
                if ok:
                    st.success(msg + "ï¼Œè¯·åˆ‡æ¢åˆ°ã€Œç™»å½•ã€ tab ç™»å½•")
                else:
                    st.error(msg)
    st.stop()

# --- 2. å·¥å…·å‡½æ•° ---

def get_latest_trading_date_ashare():
    try:
        trade_date_df = ak.tool_trade_date_hist_sina()
        current_date = datetime.now().date()
        past_trading_days = trade_date_df[trade_date_df['trade_date'] < current_date]
        return past_trading_days.iloc[-1]['trade_date'] if not past_trading_days.empty else None
    except:
        return datetime.now().date() - timedelta(days=1)

def _calc_ema(series: pd.Series, span: int) -> pd.Series:
    return series.ewm(span=span, adjust=False).mean()

def _calc_macd(close: pd.Series, fast=12, slow=26, signal=9):
    ema_fast = _calc_ema(close, fast)
    ema_slow = _calc_ema(close, slow)
    dif = ema_fast - ema_slow
    dea = _calc_ema(dif, signal)
    macd_bar = (dif - dea) * 2
    return dif, dea, macd_bar

def _calc_rsi(close: pd.Series, period=14) -> pd.Series:
    delta = close.diff()
    gain = delta.where(delta > 0, 0.0)
    loss = (-delta).where(delta < 0, 0.0)
    avg_gain = gain.ewm(alpha=1/period, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/period, adjust=False).mean()
    rs = avg_gain / avg_loss.replace(0, 1e-10)
    return 100 - (100 / (1 + rs))

def check_market_trend():
    """
    æ ¹æ®å¸‚åœºç¯å¢ƒåˆ¤æ–­å¤§ç›˜çŠ¶æ€ï¼Œå¹¶ç»™å‡ºæ¨èæŒ‡æ ‡ä¸æ“ä½œé€»è¾‘ï¼š
    - æ˜æ˜¾è¶‹åŠ¿ï¼ˆç‰›/ç†Šï¼‰ï¼šè¶‹åŠ¿ç±»æŒ‡æ ‡ MA/MACD/ADXï¼Œé¡ºåŠ¿æŒæœ‰ï¼Œå‡çº¿æ”¯æ’‘/å‹åŠ›
    - æ¨ªç›˜éœ‡è¡ï¼šåŠ¨é‡ç±» RSI/KDJ/WRï¼Œé«˜æŠ›ä½å¸ï¼Œå…³æ³¨è¶…ä¹°è¶…å–
    - è¶‹åŠ¿åè½¬ç‚¹ï¼šMACD+RSI/KDJ ç»„åˆï¼ŒèƒŒç¦»é¢„è­¦ + è¶‹åŠ¿ç¡®è®¤
    """
    try:
        # ä¼˜å…ˆç”¨æ—¥çº¿åˆ¤æ–­ç¯å¢ƒï¼ˆæŒ‡æ ‡æ›´ç¨³å®šï¼‰
        df = ak.stock_zh_index_daily(symbol="sh000001")
        if df is None or df.empty or len(df) < 60:
            # å›é€€ï¼šç”¨ 5 åˆ†é’Ÿæ•°æ®ä»…åšç®€å•è¶‹åŠ¿
            df_min = ak.stock_zh_a_minute(symbol="sh000001", period='5', adjust='qfq')
            if df_min.empty:
                return "æ— æ³•è·å–å¤§ç›˜æ•°æ®"
            df_min['ma5'] = df_min['close'].rolling(5).mean()
            df_min['ma20'] = df_min['close'].rolling(20).mean()
            last = df_min.iloc[-1]
            direction = "UP" if (last['ma5'] > last['ma20'] and last['close'] > last['ma20']) else "DOWN/éœ‡è¡"
            return f"å¤§ç›˜è¶‹åŠ¿ï¼š{direction} (æ”¶ç›˜:{last['close']}, MA20:{last['ma20']:.2f}) [æ•°æ®ä¸è¶³ï¼Œä»…åˆ†é’Ÿçº§]"

        df = df.sort_values('date').reset_index(drop=True)
        close = df['close']
        df['ma5'] = close.rolling(5).mean()
        df['ma20'] = close.rolling(20).mean()
        dif, dea, macd_bar = _calc_macd(close)
        df['macd_dif'] = dif
        df['macd_dea'] = dea
        df['macd_bar'] = macd_bar
        df['rsi'] = _calc_rsi(close, 14)

        # å–æœ€è¿‘ä¸€æ®µç”¨äºåˆ¤æ–­ï¼ˆçº¦ 20 æ—¥ï¼‰
        lookback = 20
        recent = df.iloc[-lookback:].copy()
        last = df.iloc[-1]
        prev = df.iloc[-2] if len(df) >= 2 else last

        price_now = last['close']
        ma5, ma20 = last['ma5'], last['ma20']
        rsi_now = last['rsi']
        macd_dif_now = last['macd_dif']
        macd_dea_now = last['macd_dea']
        macd_gold = (prev['macd_dif'] <= prev['macd_dea']) and (last['macd_dif'] > last['macd_dea'])
        macd_death = (prev['macd_dif'] >= prev['macd_dea']) and (last['macd_dif'] < last['macd_dea'])

        # å‡çº¿ç²˜åˆåº¦ï¼šæ¨ªç›˜æ—¶ MA5 ä¸ MA20 æ¥è¿‘
        ma_spread_pct = abs(ma5 - ma20) / ma20 * 100 if ma20 and ma20 > 0 else 99
        is_sideways_ma = ma_spread_pct < 1.5
        is_rsi_neutral = 40 <= rsi_now <= 60

        # èƒŒç¦»æ£€æµ‹ï¼šè¿‘æœŸä»·æ ¼é«˜ç‚¹ vs å‰ä¸€æ®µé«˜ç‚¹ï¼›RSI å¯¹åº”æ˜¯å¦æœªåˆ›æ–°é«˜/æ–°ä½
        high_win = 5
        recent_high_idx = recent['high'].idxmax()
        recent_high_price = recent.loc[recent_high_idx, 'high']
        recent_high_rsi = recent.loc[recent_high_idx, 'rsi']
        prev_win = df.iloc[-lookback - 30:-lookback] if len(df) >= lookback + 30 else df.iloc[:max(0, len(df) - lookback)]
        if len(prev_win) >= 10:
            prev_high_idx = prev_win['high'].idxmax()
            prev_high_price = prev_win.loc[prev_high_idx, 'high']
            prev_high_rsi = prev_win.loc[prev_high_idx, 'rsi']
            top_divergence = recent_high_price > prev_high_price and recent_high_rsi < prev_high_rsi - 3
            prev_low_idx = prev_win['low'].idxmin()
            prev_low_price = prev_win.loc[prev_low_idx, 'low']
            prev_low_rsi = prev_win.loc[prev_low_idx, 'rsi']
            recent_low_idx = recent['low'].idxmin()
            recent_low_price = recent.loc[recent_low_idx, 'low']
            recent_low_rsi = recent.loc[recent_low_idx, 'rsi']
            bottom_divergence = recent_low_price < prev_low_price and recent_low_rsi > prev_low_rsi + 3
        else:
            top_divergence = bottom_divergence = False

        # åˆ¤å®šç¯å¢ƒä¸å»ºè®®
        env = "æœªçŸ¥"
        recommend = ""
        logic = ""

        if top_divergence or bottom_divergence:
            env = "è¶‹åŠ¿åè½¬é¢„è­¦"
            recommend = "ç»„åˆä½¿ç”¨ï¼šMACD + RSI/KDJ"
            if top_divergence:
                logic = "é¡¶èƒŒç¦»ï¼šä»·æ ¼åˆ›æ–°é«˜ä½† RSI æœªåˆ›æ–°é«˜ï¼Œè­¦æƒ•è§é¡¶ï¼›ç­‰å¾… MACD æ­»å‰ç¡®è®¤åå†è€ƒè™‘å‡ä»“ã€‚"
            else:
                logic = "åº•èƒŒç¦»ï¼šä»·æ ¼åˆ›æ–°ä½ä½† RSI æœªæ–°ä½ï¼Œå…³æ³¨è§åº•æœºä¼šï¼›ç­‰å¾… MACD é‡‘å‰ç¡®è®¤åå†è€ƒè™‘ä»‹å…¥ã€‚"
        elif is_sideways_ma or is_rsi_neutral:
            env = "æ¨ªç›˜éœ‡è¡"
            recommend = "åŠ¨é‡ç±»ï¼šRSIã€KDJã€WR"
            logic = "é«˜æŠ›ä½å¸ï¼Œå…³æ³¨è¶…ä¹°(RSI>70)ã€è¶…å–(RSI<30)åŒºåŸŸçš„åè½¬ä¿¡å·ï¼Œå¿½ç•¥è¶‹åŠ¿ç±»è¿½æ¶¨æ€è·Œã€‚"
        elif (ma5 > ma20 and price_now > ma20 and macd_dif_now > macd_dea_now):
            env = "æ˜æ˜¾ä¸Šå‡è¶‹åŠ¿ï¼ˆåç‰›ï¼‰"
            recommend = "è¶‹åŠ¿ç±»ï¼šMAã€MACDã€ADX"
            logic = "é¡ºåŠ¿æŒæœ‰ï¼Œä»¥å‡çº¿ä¸ºæ”¯æ’‘/åŠ ä»“å‚è€ƒï¼Œå¿½ç•¥è¶…ä¹°è¶…å–å™ªéŸ³ï¼›ç ´ä½ MA20 å†è€ƒè™‘æ­¢ç›ˆæˆ–å‡ä»“ã€‚"
        elif (ma5 < ma20 and price_now < ma20 and macd_dif_now < macd_dea_now):
            env = "æ˜æ˜¾ä¸‹é™è¶‹åŠ¿ï¼ˆåç†Šï¼‰"
            recommend = "è¶‹åŠ¿ç±»ï¼šMAã€MACDã€ADX"
            logic = "é¡ºåŠ¿è§‚æœ›æˆ–é˜²å®ˆï¼Œåå¼¹è‡³å‡çº¿å‹åŠ›å‡ä»“ï¼Œä¸æŠ„åº•ï¼›ç­‰ MACD é‡‘å‰+ç«™ä¸Š MA20 å†è€ƒè™‘å‚ä¸ã€‚"
        else:
            env = "è¶‹åŠ¿ä¸æ˜ç¡®/è¿‡æ¸¡"
            recommend = "ç»„åˆä½¿ç”¨ï¼šMACD + RSI/KDJ"
            logic = "å¯è§‚æœ›æˆ–è½»ä»“ï¼Œç­‰å¾…è¶‹åŠ¿æ˜æœ—ï¼ˆå‡çº¿å¤šå¤´/ç©ºå¤´æ’åˆ—ï¼‰æˆ–å‡ºç°æ˜ç¡®èƒŒç¦»/é‡‘å‰æ­»å‰å†æ“ä½œã€‚"

        summary = (
            f"ã€å¸‚åœºç¯å¢ƒã€‘{env}\n"
            f"ã€æ¨èæŒ‡æ ‡ã€‘{recommend}\n"
            f"ã€æ“ä½œé€»è¾‘ã€‘{logic}\n"
            f"ã€å½“å‰æ•°æ®ã€‘æ”¶ç›˜:{price_now:.2f} | MA5:{ma5:.2f} MA20:{ma20:.2f} | RSI:{rsi_now:.1f} | MACD:{'é‡‘å‰' if macd_gold else 'æ­»å‰' if macd_death else 'ä¸­æ€§'}"
        )
        return summary
    except Exception as e:
        return f"å¤§ç›˜æ£€æµ‹å‡ºé”™: {e}"

def get_market_symbol(stock_code: str) -> str:
    stock_code = str(stock_code).strip()
    if stock_code.startswith('6'): return 'sh'
    elif stock_code.startswith('00') or stock_code.startswith('3'): return 'sz'
    elif stock_code.startswith('8') or stock_code.startswith('4'): return 'bj'
    return 'sh'


def _fetch_global_news_for_sectors():
    """
    æ‹‰å–åŒèŠ±é¡º + ä¸œæ–¹è´¢å¯Œå…¨çƒè¦é—»ï¼Œåˆå¹¶ä¸ºä¸€æ®µæ–‡æœ¬ï¼Œä¾›çƒ­é—¨æ¿å—æ€»ç»“ä¸å›ç­”ä½¿ç”¨ã€‚
    è¿”å› (combined_text, error_msg)ã€‚error_msg ä¸ºç©ºè¡¨ç¤ºæ— è‡´å‘½é”™è¯¯ã€‚
    """
    parts = []
    try:
        ths = ak.stock_info_global_ths()
        if ths is not None and not ths.empty:
            for _, row in ths.head(15).iterrows():
                title = row.get("æ ‡é¢˜", row.get("æ ‡é¢˜å", row.get("title", "")))
                ts = row.get("æ—¶é—´", row.get("å‘å¸ƒæ—¶é—´", row.get("date", "")))
                body = row.get("å†…å®¹", row.get("æ‘˜è¦", row.get("æ–°é—»å†…å®¹", row.get("content", ""))))
                parts.append(f"[åŒèŠ±é¡º] {ts} æ ‡é¢˜ï¼š{title}\n{body}")
    except Exception as e:
        parts.append(f"[åŒèŠ±é¡ºå…¨çƒè¦é—»è·å–å¤±è´¥: {e}]")
    try:
        em = getattr(ak, "stock_info_global_em", None)
        if callable(em):
            df_em = em()
            if df_em is not None and not df_em.empty:
                for _, row in df_em.head(15).iterrows():
                    title = row.get("æ ‡é¢˜", row.get("æ ‡é¢˜å", row.get("title", "")))
                    ts = row.get("æ—¶é—´", row.get("å‘å¸ƒæ—¶é—´", row.get("date", "")))
                    body = row.get("å†…å®¹", row.get("æ‘˜è¦", row.get("æ–°é—»å†…å®¹", row.get("content", ""))))
                    parts.append(f"[ä¸œæ–¹è´¢å¯Œ] {ts} æ ‡é¢˜ï¼š{title}\n{body}")
    except Exception as e:
        parts.append(f"[ä¸œæ–¹è´¢å¯Œå…¨çƒè¦é—»è·å–å¤±è´¥: {e}]")
    combined = "\n\n".join(parts) if parts else "æš‚æ— å…¨çƒè¦é—»æ•°æ®"
    return _fix_mojibake_utf8(combined), ""


def _fix_mojibake_utf8(text: str) -> str:
    """
    ä¿®å¤ã€ŒUTF-8 è¢«è¯¯å½“ä½œ Latin-1/CP1252 è§£ç ã€å¯¼è‡´çš„ä¹±ç ï¼ˆå¤šç»´åº¦æƒ…æŠ¥ç­‰æ¥å£å¸¸è§ï¼‰ã€‚
    å…ˆæ•´æ®µå°è¯•ï¼›å¤±è´¥åˆ™æŒ‰è¡Œå°è¯•ï¼Œé¿å…æ··åˆç¼–ç æ—¶æ•´æ®µæŠ¥é”™ã€‚
    """
    if not text or not isinstance(text, str):
        return text or ""

    def _decode(s: str) -> str:
        try:
            return s.encode("latin-1").decode("utf-8")
        except (UnicodeDecodeError, UnicodeEncodeError, AttributeError):
            return s

    try:
        return _decode(text)
    except Exception:
        pass
    # æŒ‰è¡Œä¿®å¤ï¼Œé¿å…éƒ¨åˆ†ä¹±ç éƒ¨åˆ†æ­£å¸¸æ—¶æ•´æ®µå¤±è´¥
    lines = text.split("\n")
    out = []
    for line in lines:
        try:
            out.append(_decode(line))
        except Exception:
            out.append(line)
    return "\n".join(out)


def run_analysis_steps_streaming(stock_code: str, stream_holder: dict):
    """
    æµå¼æ‰§è¡Œï¼šæ¯æ­¥ yield å®é™…æ•°æ®å†…å®¹ï¼ˆæ—  Step æ ‡é¢˜ï¼‰ï¼Œå¹¶çº³å…¥ run.py çš„å¤§ç›˜ã€çƒ­é—¨æ¿å—ã€ä¸ªè‚¡ã€é¾™è™æ¦œã€æ–°é—»ã€‚
    stream_holder å›å¡« analysis_resultã€news_contextã€mar_infoã€val_boardsã€ind_infoã€cap_infoã€news_text_ak ç­‰ä¾›æ‹¼ promptã€‚
    """
    code = stock_code.strip()
    pipeline = StockAnalysisPipeline()
    stock_name = STOCK_NAME_MAP.get(code, "") or f"è‚¡ç¥¨{code}"
    realtime_quote = None
    chip_data = None
    trend_result = None
    news_context = None
    enhanced_context = None
    context = None

    # ----- æ—¥çº¿æ•°æ® -----
    yield "### ğŸ“Š æ—¥çº¿æ•°æ®\n"
    success, error = pipeline.fetch_and_save_stock_data(code)
    daily_status = "æ—¥çº¿æ•°æ®å·²è·å–/æ ¡éªŒå®Œæˆ" if success else f"æ—¥çº¿è·å–å¤±è´¥: {error}"
    stream_holder["daily_status"] = daily_status
    if success:
        yield f"{daily_status}ã€‚\n\n"
    else:
        yield f"{daily_status}\n\n"

    # ----- å¤§ç›˜ç¯å¢ƒï¼ˆåŒ run.pyï¼‰-----
    yield "### ğŸ“ˆ å¤§ç›˜ç¯å¢ƒ\n"
    mar_info = check_market_trend()
    stream_holder["mar_info"] = mar_info
    yield f"{mar_info}\n\n"

    # # ----- ä»Šæ—¥çƒ­é—¨æ¿å—ï¼ˆåŒ run.pyï¼‰-----
    # yield "### ğŸ·ï¸ ä»Šæ—¥çƒ­é—¨æ¿å—\n"
    # try:
    #     csv_path = f'data/board/{datetime.now().strftime("%Y%m%d")}_close_select.csv'
    #     if os.path.exists(csv_path):
    #         val_boards_df = pd.read_csv(csv_path)
    #         val_boards = list(val_boards_df["board"])[:5]
    #         val_boards_str = ", ".join(val_boards)
    #         stream_holder["val_boards"] = "çƒ­é—¨æ¿å—ï¼š" + val_boards_str
    #         yield f"{val_boards_str}\n\n"
    #     else:
    #         stream_holder["val_boards"] = "ï¼ˆæœ¬åœ°æ¿å—æ•°æ®æœªæ›´æ–°ï¼‰"
    #         yield "ä»Šæ—¥æ¿å—æ•°æ®æœªæ›´æ–°\n\n"
    # except Exception:
    #     stream_holder["val_boards"] = "æš‚æ— çƒ­é—¨æ¿å—æ•°æ®"
    #     yield "æš‚æ— çƒ­é—¨æ¿å—æ•°æ®\n\n"

    # ----- å®æ—¶è¡Œæƒ… -----
    yield "### ğŸ’¹ å®æ—¶è¡Œæƒ…\n"
    realtime_info = "æœªè·å–åˆ°å®æ—¶è¡Œæƒ…"
    try:
        realtime_quote = pipeline.fetcher_manager.get_realtime_quote(code)
        if realtime_quote:
            if realtime_quote.name:
                stock_name = realtime_quote.name
            price = getattr(realtime_quote, "price", None)
            vol_ratio = getattr(realtime_quote, "volume_ratio", None)
            turnover = getattr(realtime_quote, "turnover_rate", None)
            realtime_info = f"{stock_name} ç°ä»· {price}ï¼Œé‡æ¯” {vol_ratio}ï¼Œæ¢æ‰‹ç‡ {turnover}%"
            stream_holder["realtime_info"] = realtime_info
            yield f"**{realtime_info}**\n\n"
        else:
            stream_holder["realtime_info"] = realtime_info
            yield f"{realtime_info}ï¼Œå°†ç”¨å†å²æ•°æ®ã€‚\n\n"
    except Exception as e:
        stream_holder["realtime_info"] = realtime_info
        yield f"å®æ—¶è¡Œæƒ…è·å–å¤±è´¥: {e}\n\n"

    # ----- ä¸ªè‚¡å½“æ—¥è¡Œæƒ…ï¼ˆåŒ run.pyï¼‰-----
    yield "### ğŸ“‹ ä¸ªè‚¡å½“æ—¥è¡Œæƒ…\n"
    cur_date = datetime.now().strftime("%Y%m%d")
    ind_info = f"{code} æœ€æ–°æ•°æ®"
    try:
        individual = ak.stock_zh_a_hist(code, start_date=cur_date)
        if not individual.empty:
            for col in individual.columns:
                ind_info += f"\n{col}ï¼š{individual.iloc[0][col]}"
            stream_holder["ind_info"] = f"{code}åˆ†æï¼š{ind_info}"
            yield f"```\n{ind_info}\n```\n\n"
        else:
            ind_info = f"{code} ä»Šæ—¥æš‚æ— è¡Œæƒ…ï¼ˆå¯èƒ½éäº¤æ˜“æ—¶é—´ï¼‰"
            stream_holder["ind_info"] = ind_info
            yield f"{ind_info}\n\n"
    except Exception as e:
        stream_holder["ind_info"] = f"ä¸ªè‚¡æ•°æ®è·å–å¤±è´¥: {e}"
        yield f"è·å–ä¸ªè‚¡æ•°æ®å¤±è´¥: {e}\n\n"

    # ----- ç­¹ç åˆ†å¸ƒ -----
    yield "### ğŸ¯ ç­¹ç åˆ†å¸ƒ\n"
    chip_info = "æœªè·å–åˆ°ç­¹ç åˆ†å¸ƒæ•°æ®"
    try:
        chip_data = pipeline.fetcher_manager.get_chip_distribution(code)
        if chip_data:
            chip_info = f"è·åˆ©æ¯”ä¾‹ {chip_data.profit_ratio:.1%}ï¼Œ90% é›†ä¸­åº¦ {chip_data.concentration_90:.2%}"
            stream_holder["chip_info"] = chip_info
            yield f"**{chip_info}**\n\n"
        else:
            stream_holder["chip_info"] = chip_info
            yield f"{chip_info}\n\n"
    except Exception as e:
        stream_holder["chip_info"] = chip_info
        yield f"ç­¹ç åˆ†å¸ƒè·å–å¤±è´¥: {e}\n\n"

    # ----- è¶‹åŠ¿åˆ†æ -----
    yield "### ğŸ“‰ è¶‹åŠ¿åˆ†æ\n"
    trend_info = "æ— å†å²è¡Œæƒ…ï¼Œæœªåšè¶‹åŠ¿åˆ†æ"
    try:
        context_for_trend = pipeline.db.get_analysis_context(code)
        if context_for_trend and context_for_trend.get("raw_data"):
            raw_data = context_for_trend["raw_data"]
            if isinstance(raw_data, list) and len(raw_data) > 0:
                df_trend = pd.DataFrame(raw_data)
                trend_result = pipeline.trend_analyzer.analyze(df_trend, code)
                trend_info = f"è¶‹åŠ¿çŠ¶æ€ {trend_result.trend_status.value}ï¼Œä¹°å…¥ä¿¡å· {trend_result.buy_signal.value}ï¼Œè¯„åˆ† {trend_result.signal_score}"
                if trend_result.signal_reasons:
                    trend_info += "ï¼›ç†ç”±ï¼š" + "ï¼›".join(trend_result.signal_reasons[:3])
                if trend_result.risk_factors:
                    trend_info += "ï¼›é£é™©ï¼š" + "ï¼›".join(trend_result.risk_factors[:2])
                stream_holder["trend_info"] = trend_info
                yield f"**{trend_result.trend_status.value}**ï¼Œä¹°å…¥ä¿¡å· **{trend_result.buy_signal.value}**ï¼Œè¯„åˆ† **{trend_result.signal_score}**\n"
                if trend_result.signal_reasons:
                    yield "ç†ç”±ï¼š" + "ï¼›".join(trend_result.signal_reasons[:3]) + "\n"
                if trend_result.risk_factors:
                    yield "é£é™©ï¼š" + "ï¼›".join(trend_result.risk_factors[:2]) + "\n"
                yield "\n"
            else:
                stream_holder["trend_info"] = trend_info
                yield "å†å²æ•°æ®ä¸ºç©ºï¼Œæœªåšè¶‹åŠ¿åˆ†æ\n\n"
        else:
            stream_holder["trend_info"] = trend_info
            yield f"{trend_info}\n\n"
    except Exception as e:
        stream_holder["trend_info"] = trend_info
        yield f"è¶‹åŠ¿åˆ†æå¤±è´¥: {e}\n\n"

    # ----- é¾™è™æ¦œä¸èµ„é‡‘ï¼ˆåŒ run.pyï¼‰-----
    yield "### ğŸ‰ é¾™è™æ¦œä¸èµ„é‡‘\n"
    market = get_market_symbol(code)
    dd = None
    try:
        latest_date = get_latest_trading_date_ashare()
        dd = latest_date.strftime("%Y%m%d") if latest_date else datetime.now().strftime("%Y%m%d")
    except Exception:
        dd = datetime.now().strftime("%Y%m%d")
    longhu_info = ""
    try:
        buyin = ak.stock_lhb_stock_detail_em(symbol=code, date=dd, flag="ä¹°å…¥")
        buyin = buyin[["äº¤æ˜“è¥ä¸šéƒ¨åç§°", "ä¹°å…¥é‡‘é¢", "ç±»å‹"]]
        for _, row in buyin.iterrows():
            longhu_info += f"ä¹°å…¥ {(int(row['ä¹°å…¥é‡‘é¢'])/(10**7)):.2f} åƒä¸‡å…ƒ â€” {row['äº¤æ˜“è¥ä¸šéƒ¨åç§°']} ({row['ç±»å‹']})\n"
    except Exception:
        longhu_info += f"{dd} é¾™è™æ¦œä¹°å…¥æœªä¸Šæ¦œ\n"
    try:
        sellout = ak.stock_lhb_stock_detail_em(symbol=code, date=dd, flag="å–å‡º")
        sellout = sellout[["äº¤æ˜“è¥ä¸šéƒ¨åç§°", "å–å‡ºé‡‘é¢", "ç±»å‹"]]
        for _, row in sellout.iterrows():
            longhu_info += f"å–å‡º {(int(row['å–å‡ºé‡‘é¢'])/(10**7)):.2f} åƒä¸‡å…ƒ â€” {row['äº¤æ˜“è¥ä¸šéƒ¨åç§°']} ({row['ç±»å‹']})\n"
    except Exception:
        longhu_info += f"{dd} é¾™è™æ¦œå–å‡ºæœªä¸Šæ¦œ\n"
    try:
        cap_flow = ak.stock_individual_fund_flow(stock=code, market=market)
        lt = get_latest_trading_date_ashare()
        if lt is not None and not cap_flow.empty:
            cap_flow["æ—¥æœŸ"] = pd.to_datetime(cap_flow["æ—¥æœŸ"]).dt.date
            row = cap_flow[cap_flow["æ—¥æœŸ"] == lt]
            if not row.empty:
                cap_ttl = row.iloc[0]["ä¸»åŠ›å‡€æµå…¥-å‡€é¢"]
                cap_info = f"ä¸»åŠ›å‡€æµå…¥-å‡€é¢ï¼š{float(cap_ttl/(10**8)):.2f} äº¿å…ƒ"
                stream_holder["cap_info"] = cap_info
                longhu_info = cap_info + "\n\n" + longhu_info
    except Exception:
        pass
    if not stream_holder.get("cap_info"):
        stream_holder["cap_info"] = "èµ„é‡‘æµå‘è·å–å¤±è´¥"
    longhu_full = longhu_info.strip() or "æš‚æ— é¾™è™æ¦œæ•°æ®"
    stream_holder["longhu_info"] = longhu_full
    yield f"```\n{longhu_full}\n```\n\n"

    # ----- å¤šç»´åº¦æƒ…æŠ¥æœç´¢ï¼ˆå±•ç¤ºæœç´¢åˆ°çš„æ­£æ–‡ï¼‰-----
    yield "### ğŸ” å¤šç»´åº¦æƒ…æŠ¥æœç´¢\n"
    if pipeline.search_service.is_available:
        try:
            intel_results = pipeline.search_service.search_comprehensive_intel(
                stock_code=code, stock_name=stock_name, max_searches=5
            )
            if intel_results:
                news_context = pipeline.search_service.format_intel_report(intel_results, stock_name)
                news_context = _fix_mojibake_utf8(news_context)
                try:
                    qctx = pipeline._build_query_context()
                    for dim_name, response in intel_results.items():
                        if response and getattr(response, "success", False) and getattr(response, "results", None):
                            pipeline.db.save_news_intel(
                                code=code, name=stock_name, dimension=dim_name,
                                query=response.query, response=response, query_context=qctx,
                            )
                except Exception:
                    pass
                yield f"```\n{news_context}\n```\n\n"
            else:
                yield "æœªè·å–åˆ°æƒ…æŠ¥ç»“æœ\n\n"
        except Exception as e:
            yield f"æƒ…æŠ¥æœç´¢å¤±è´¥: {e}\n\n"
    else:
        yield "æœç´¢æœåŠ¡æœªé…ç½®ï¼Œè·³è¿‡æƒ…æŠ¥æœç´¢\n\n"

    # ----- è¿‘æœŸæ–°é—»ï¼ˆAkShare è¿‘ 3 å¤©ï¼ŒåŒ run.pyï¼‰-----
    yield "### ğŸ“° è¿‘æœŸæ–°é—»ï¼ˆè¿‘ 3 å¤©ï¼‰\n"
    news_text_ak = "æš‚æ— è¿‘æœŸæ–°é—»"
    try:
        stock_news = ak.stock_news_em(symbol=code)
        stock_news["å‘å¸ƒæ—¶é—´"] = pd.to_datetime(stock_news["å‘å¸ƒæ—¶é—´"], errors="coerce")
        recent = stock_news[stock_news["å‘å¸ƒæ—¶é—´"] >= (datetime.now() - timedelta(days=3))]
        if not recent.empty:
            news_text_ak = ""
            for _, row in recent.head(10).iterrows():
                news_text_ak += f"{row['å‘å¸ƒæ—¶é—´']}\næ ‡é¢˜ï¼š{row['æ–°é—»æ ‡é¢˜']}\nå†…å®¹ï¼š{row['æ–°é—»å†…å®¹']}\næ¥æºï¼š{row['æ–‡ç« æ¥æº']}\n\n"
            stream_holder["news_text_ak"] = news_text_ak
            yield f"```\n{news_text_ak.strip()}\n```\n\n"
        else:
            stream_holder["news_text_ak"] = news_text_ak
            yield f"{news_text_ak}\n\n"
    except Exception as e:
        stream_holder["news_text_ak"] = news_text_ak
        yield f"æ–°é—»è·å–å¤±è´¥: {e}\n\n"

    # åŒèŠ±é¡º/ä¸œæ–¹è´¢å¯Œå…¨çƒè¦é—»ä¸åœ¨åˆå§‹åˆ†æä¸­æ‹‰å–ï¼Œä»…åœ¨ç”¨æˆ·è¿½é—®ã€Œæ–°é—»ã€ã€Œæ¶ˆæ¯ã€ã€Œæ¿å—ã€æ—¶å†æ‹‰å–å¹¶æ€»ç»“çƒ­é—¨æ¿å—

    # ----- åˆ†æä¸Šä¸‹æ–‡ä¸å¢å¼º -----
    context = pipeline.db.get_analysis_context(code)
    if context is None:
        context = {
            "code": code, "stock_name": stock_name, "date": date_type.today().isoformat(),
            "data_missing": True, "today": {}, "yesterday": {},
        }
    enhanced_context = pipeline._enhance_context(
        context, realtime_quote, chip_data, trend_result, stock_name
    )

    # ----- AI åˆ†æç»“è®º -----
    yield "### ğŸ¤– AI åˆ†æç»“è®º\n"
    try:
        result = pipeline.analyzer.analyze(enhanced_context, news_context=news_context)
        if result:
            stream_holder["analysis_result"] = result
            stream_holder["news_context"] = news_context
            stream_holder["stock_name"] = stock_name
            stream_holder["enhanced_context"] = enhanced_context
            yield f"**æ“ä½œå»ºè®®**ï¼š{result.operation_advice}\n\n**æƒ…ç»ªè¯„åˆ†**ï¼š{result.sentiment_score}\n\n"
            if getattr(result, "analysis_summary", None):
                yield f"{result.analysis_summary}\n\n"
        else:
            yield "AI åˆ†æè¿”å›ä¸ºç©º\n\n"
    except Exception as e:
        yield f"AI åˆ†æå¤±è´¥: {e}\n\n"

    # ----- ä¿å­˜åˆ†æå†å² -----
    if stream_holder.get("analysis_result"):
        try:
            ctx_snapshot = pipeline._build_context_snapshot(
                enhanced_context=enhanced_context, news_content=news_context,
                realtime_quote=realtime_quote, chip_data=chip_data,
            )
            pipeline.db.save_analysis_history(
                result=stream_holder["analysis_result"],
                query_id=pipeline.query_id or "",
                report_type=ReportType.FULL.value,
                news_content=news_context,
                context_snapshot=ctx_snapshot,
                save_snapshot=getattr(pipeline.config, "save_context_snapshot", True),
            )
            yield "å·²ä¿å­˜åˆ†æå†å²ã€‚\n\n"
        except Exception as e:
            yield f"ä¿å­˜åˆ†æå†å²å¤±è´¥: {e}\n\n"


# --- 3. åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ---

if "messages" not in st.session_state:
    st.session_state.messages = []

if "enable_web_search" not in st.session_state:
    st.session_state.enable_web_search = False


def _get_chat_config():
    """è‹¥ç”¨æˆ·å¼€å¯è”ç½‘æœç´¢ï¼Œåˆ™è¿”å›å¸¦ Google Search çš„ configï¼Œå¦åˆ™è¿”å› Noneï¼ˆä½¿ç”¨é»˜è®¤ï¼‰ã€‚"""
    if st.session_state.get("enable_web_search"):
        try:
            return types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())]
            )
        except Exception:
            return None
    return None

# ç¡®ä¿åªæœ‰åœ¨ client æˆåŠŸåˆå§‹åŒ–åæ‰åˆ›å»º chat_session
if client and "chat_session" not in st.session_state:
    try:
        # å¯åŠ¨ Gemini çš„èŠå¤©ä¼šè¯ï¼Œmodel åç§°è¯·æ ¹æ®å®é™…å¯ç”¨æ¨¡å‹è°ƒæ•´
        st.session_state.chat_session = client.chats.create(model="gemini-3-pro-preview")
    except Exception as e:
        st.error(f"æ— æ³•åˆå§‹åŒ–èŠå¤©ä¼šè¯: {e}")

# --- 4. ä¾§è¾¹æ ï¼šå‚æ•°é…ç½® ---

with st.sidebar:
    st.title("âš™ï¸ é…ç½®å‚æ•°")
    _user = st.session_state.current_user
    if _user:
        st.caption(f"ğŸ‘¤ {_user['username']}")
        if st.button("é€€å‡ºç™»å½•"):
            st.session_state.current_user = None
            st.rerun()
    st.divider()
    stock_code = st.text_input("è‚¡ç¥¨ä»£ç ", placeholder="ä¾‹å¦‚: 601616")
    
    default_prompt = """ç®€çŸ­æ€»ç»“ï¼Œç»™å‡ºæœ€ç›´æ¥çš„æ“ä½œå»ºè®®ã€‚

ã€å†³ç­– = åŠ¨åŠ›ï¼ˆå…·ä½“ç†ç”±ï¼‰ > é˜»åŠ›ï¼ˆå…·ä½“é£é™©ï¼‰ã€‘ã€‚
ç»™å‡ºã€å¤±æ•ˆæ¡ä»¶ã€‘ï¼ˆæ­¢æŸé€»è¾‘ï¼‰ã€‚"""
    
    user_system_prompt = st.text_area("åˆ†ææŒ‡ä»¤ (System Prompt)", value=default_prompt, height=300)

    st.session_state.enable_web_search = st.checkbox(
        "ğŸ” è”ç½‘æœç´¢",
        value=st.session_state.get("enable_web_search", False),
        help="å¼€å¯åï¼Œå¯¹è¯æ—¶å¯ä½¿ç”¨ Google æœç´¢è·å–å®æ—¶ä¿¡æ¯ï¼ˆéœ€é¢å¤–è®¡è´¹ï¼‰",
    )

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        if client:
            st.session_state.chat_session = client.chats.create(model="gemini-2.0-flash")
        st.rerun()

# --- 5. ä¸»ç•Œé¢å¸ƒå±€ ---

st.title("ğŸ“ˆ æ™ºèƒ½è‚¡ç¥¨åˆ†æåŠ©æ‰‹")
st.caption("åŸºäº Gemini 2.0 Flash ä¸ AkShare å®æ—¶æ•°æ®")

# å…è´£å£°æ˜
# st.warning("âš ï¸ **é£é™©æç¤º**ï¼šæœ¬å·¥å…·ç”Ÿæˆçš„å†…å®¹ä»…ä¾›æŠ€æœ¯äº¤æµä¸å‚è€ƒï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚è‚¡å¸‚æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚")

# å±•ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# åˆå§‹åˆ†æé€»è¾‘ï¼šç‚¹å‡»æŒ‰é’®è§¦å‘ç¬¬ä¸€æ¬¡æ·±åº¦åˆ†æ
if st.button("ğŸš€ å¼€å§‹æ·±åº¦åˆ†æ", type="primary"):
    if not client:
        st.error("Gemini Client åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Keyã€‚")
    elif not stock_code:
        st.error("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")
    else:
        # æµå¼å±•ç¤ºï¼šæ¯æ­¥ yield ä¸€æ®µå†…å®¹ï¼Œå‚è€ƒ run.py çš„æµå¼è¾“å‡º
        stream_holder = {}
        steps_container = st.empty()
        full_response = ""
        with st.status("æ­£åœ¨æœé›†å¤šç»´æ•°æ®...", expanded=True) as status:
            for chunk in run_analysis_steps_streaming(stock_code, stream_holder):
                full_response += chunk
                steps_container.markdown(full_response)
            status.update(label="æ•°æ®å‡†å¤‡å°±ç»ªï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...", state="complete")

        # ç”¨æµå¼é˜¶æ®µå·²å†™å…¥çš„ stream_holder æ‹¼ promptï¼ˆä¸é¡µé¢å¯¹é½ï¼šå±•ç¤ºè¿‡çš„å…¨éƒ¨è¿› full_contextï¼‰
        mar_info = stream_holder.get("mar_info") or check_market_trend()
        val_boards = stream_holder.get("val_boards") or "æš‚æ— çƒ­é—¨æ¿å—æ•°æ®"
        ind_info = stream_holder.get("ind_info") or f"{stock_code} æš‚æ— è¡Œæƒ…"
        cap_info = stream_holder.get("cap_info") or "èµ„é‡‘æµå‘è·å–å¤±è´¥"
        news_intel = (stream_holder.get("news_context") or "").strip() or "æœªåšå¤šç»´åº¦æƒ…æŠ¥æœç´¢"
        news_text_ak = stream_holder.get("news_text_ak") or "æš‚æ— è¿‘æœŸæ–°é—»"
        daily_status = stream_holder.get("daily_status") or ""
        realtime_info = stream_holder.get("realtime_info") or "æœªè·å–åˆ°å®æ—¶è¡Œæƒ…"
        chip_info = stream_holder.get("chip_info") or "æœªè·å–åˆ°ç­¹ç åˆ†å¸ƒ"
        trend_info = stream_holder.get("trend_info") or "æœªåšè¶‹åŠ¿åˆ†æ"
        longhu_info = stream_holder.get("longhu_info") or "æš‚æ— é¾™è™æ¦œæ•°æ®"

        # ç»„è£…å‘é€ç»™ Gemini çš„åˆå§‹ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«æ‰€æœ‰å±•ç¤ºè¿‡çš„æ•°æ®ï¼Œä¸å«å…¨çƒè¦é—»ï¼Œè¿½é—®æ—¶å†æŒ‰éœ€æ‹‰å–ï¼‰
        full_context = f"""
        ä½ æ˜¯ä¸€ä¸ªèµ„æ·±Aè‚¡åˆ†æå‘˜ã€‚
        è‚¡ç¥¨ä»£ç : {stock_code}
        å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        ã€æ—¥çº¿æ•°æ®ã€‘: {daily_status}
        ã€å¤§ç›˜ç¯å¢ƒã€‘: {mar_info}
        ã€çƒ­é—¨æ¿å—ã€‘: {val_boards}
        ã€å®æ—¶è¡Œæƒ…ã€‘: {realtime_info}
        ã€ä¸ªè‚¡å½“æ—¥è¡Œæƒ…ã€‘: {ind_info}
        ã€ç­¹ç åˆ†å¸ƒã€‘: {chip_info}
        ã€è¶‹åŠ¿åˆ†æã€‘: {trend_info}
        ã€èµ„é‡‘é¢ã€‘: {cap_info}
        ã€é¾™è™æ¦œæ˜ç»†ã€‘:
        {longhu_info}
        
        ã€å¤šç»´åº¦æƒ…æŠ¥æœç´¢ã€‘:
        {news_intel}
        
        ã€è¿‘æœŸæ–°é—»ï¼ˆè¿‘3å¤©ï¼‰ã€‘:
        {news_text_ak}
        
        è¯·ç»“åˆä»¥ä¸Šå…¨éƒ¨æ•°æ®ï¼Œæ‰§è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼š
        {user_system_prompt}
        è¾“å‡ºè¦æ±‚æ¼‚äº®çš„markdownæ ¼å¼ã€‚
        """

        # è°ƒç”¨ Gemini å¹¶æµå¼å±•ç¤º
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            full_response = ""
            
            try:
                # å‘é€ç»™ Chat Sessionï¼ˆè‹¥å¼€å¯è”ç½‘æœç´¢åˆ™ä¼ å…¥å¸¦ Google Search çš„ configï¼‰
                chat_config = _get_chat_config()
                responses = st.session_state.chat_session.send_message_stream(
                    full_context, config=chat_config
                )
                for chunk in responses:
                    full_response += chunk.text
                    response_placeholder.markdown(full_response)
                
                # è®°å½•å†å²
                st.session_state.messages.append({"role": "user", "content": f"åˆ†æè‚¡ç¥¨ {stock_code}"})
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                # ç”¨é‡ç›‘æ§
                if st.session_state.current_user:
                    record_usage(
                        st.session_state.current_user["id"],
                        st.session_state.current_user["username"],
                        "analysis",
                        stock_code,
                    )
            except Exception as e:
                st.error(f"API è°ƒç”¨å‡ºé”™: {e}")

# --- 6. å¤šè½®è¿½é—®èŠå¤©æ¡† ---
def _user_asks_news_or_sectors(prompt: str) -> bool:
    """ç”¨æˆ·æ˜¯å¦åœ¨é—®æ–°é—»ã€æ¶ˆæ¯æˆ–æ¿å—ï¼ˆéœ€æ‹‰å–å…¨çƒè¦é—»å¹¶æ€»ç»“çƒ­é—¨æ¿å—ï¼‰"""
    if not prompt or not isinstance(prompt, str):
        return False
    p = prompt.strip()
    return "æ–°é—»" in p or "æ¶ˆæ¯" in p or "æ¿å—" in p


if prompt := st.chat_input("æ‚¨å¯ä»¥ç»§ç»­è¿½é—®ï¼Œä¾‹å¦‚ï¼š'å¦‚æœç¼©é‡äº†æ€ä¹ˆåŠï¼Ÿ' æˆ– 'è¯¦ç»†è§£é‡Šä¸€ä¸‹èµ„é‡‘é¢'"):
    if not client:
        st.error("Client æœªè¿æ¥")
    else:
        # å±•ç¤ºç”¨æˆ·æé—®
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # AI å›å¤
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            full_response = ""

            if _user_asks_news_or_sectors(prompt):
                # å…ˆæ‹‰å–åŒèŠ±é¡º + ä¸œæ–¹è´¢å¯Œå…¨çƒè¦é—»ï¼Œæ€»ç»“çƒ­é—¨æ¿å—ï¼Œyield ç»™ç”¨æˆ·åå†ç»“åˆæ–°é—»ä¸æ¿å—å›ç­”
                with st.status("æ­£åœ¨æ‹‰å–åŒèŠ±é¡ºä¸ä¸œæ–¹è´¢å¯Œå…¨çƒè¦é—»â€¦", expanded=True):
                    news_combined, _ = _fetch_global_news_for_sectors()
                # ç”¨ Gemini æ ¹æ®æ–°é—»æ€»ç»“å½“å‰çƒ­ç‚¹æ¿å—ï¼ˆä¸€æ¬¡éæµå¼è°ƒç”¨ï¼‰
                hot_sectors_summary = "æš‚æ— çƒ­é—¨æ¿å—æ€»ç»“"
                try:
                    summary_prompt = f"""æ ¹æ®ä»¥ä¸‹å…¨çƒè¦é—»å†…å®¹ï¼Œç”¨ä¸€ä¸¤æ®µè¯æ€»ç»“å½“å‰Aè‚¡å¸‚åœºçƒ­ç‚¹æ¿å—ï¼ˆåˆ—å‡ºæ¿å—åç§°å¹¶ç®€è¦è¯´æ˜åŸå› ï¼‰ã€‚åªè¾“å‡ºæ€»ç»“å†…å®¹ï¼Œä¸è¦å¤è¿°æ–°é—»å…¨æ–‡ã€‚

æ–°é—»ä¸è¦é—»ï¼š
{news_combined[:12000]}
"""
                    gen = client.models.generate_content(
                        model="gemini-2.0-flash",
                        contents=summary_prompt,
                        config=types.GenerateContentConfig(temperature=0.3),
                    )
                    if gen and gen.text:
                        hot_sectors_summary = gen.text.strip()
                except Exception as e:
                    hot_sectors_summary = f"çƒ­é—¨æ¿å—æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}ï¼Œå°†ä»…åŸºäºæ–°é—»åŸæ–‡å›ç­”ã€‚"
                # å…ˆ yield çƒ­é—¨æ¿å—ç»™ç”¨æˆ·
                full_response = "### çƒ­é—¨æ¿å—æ€»ç»“\n\n" + hot_sectors_summary + "\n\n---\n\n"
                response_placeholder.markdown(full_response)
                # å†ç»“åˆæ–°é—»ä¸çƒ­é—¨æ¿å—æ€»ç»“ï¼Œæµå¼å›ç­”ç”¨æˆ·é—®é¢˜
                augmented_prompt = f"""è¯·ç»“åˆä»¥ä¸‹ã€Œçƒ­é—¨æ¿å—æ€»ç»“ã€ä¸ã€Œæ–°é—»æ‘˜è¦ã€å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å…ˆå¯ç®€è¦å‘¼åº”çƒ­ç‚¹ï¼Œå†é’ˆå¯¹ç”¨æˆ·é—®é¢˜ç»™å‡ºåˆ†æã€‚

ã€çƒ­é—¨æ¿å—æ€»ç»“ã€‘
{hot_sectors_summary}

ã€æ–°é—»æ‘˜è¦ã€‘
{news_combined[:8000]}

ç”¨æˆ·é—®é¢˜ï¼š{prompt}
"""
                try:
                    chat_config = _get_chat_config()
                    responses = st.session_state.chat_session.send_message_stream(
                        augmented_prompt, config=chat_config
                    )
                    for chunk in responses:
                        full_response += chunk.text
                        response_placeholder.markdown(full_response)
                except Exception as e:
                    full_response += f"\n\nå›å¤å‡ºé”™: {e}"
                    response_placeholder.markdown(full_response)
            else:
                try:
                    chat_config = _get_chat_config()
                    responses = st.session_state.chat_session.send_message_stream(
                        prompt, config=chat_config
                    )
                    for chunk in responses:
                        full_response += chunk.text
                        response_placeholder.markdown(full_response)
                except Exception as e:
                    st.error(f"å›å¤å‡ºé”™: {e}ã€‚å¯èƒ½è¿æ¥å·²æ–­å¼€ï¼Œè¯·å°è¯•ç‚¹å‡»å·¦ä¾§'æ¸…ç©ºå¯¹è¯'æŒ‰é’®ã€‚")

            if full_response:
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                # ç”¨é‡ç›‘æ§
                if st.session_state.current_user:
                    record_usage(
                        st.session_state.current_user["id"],
                        st.session_state.current_user["username"],
                        "follow_up",
                        None,
                    )